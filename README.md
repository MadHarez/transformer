# Transformer 翻译模型

基于Transformer架构的英中翻译模型，使用了改进的训练策略和优化技术。

## 项目结构

```
Translation/
├── data/                   # 数据文件
│   ├── MDN_Web_Docs.en-zh_CN.en    # 英文语料
│   ├── MDN_Web_Docs.en-zh_CN.zh_CN # 中文语料
│   └── ...
├── model.py               # Transformer模型定义
├── data_utils.py          # 数据处理工具
├── train.py              # 训练脚本（已改进）
├── evaluate.py           # 评估脚本（已更新）
├── inference.py          # 推理脚本（已更新）
├── config.py             # 训练配置文件
├── checkpoints/          # 模型检查点目录
├── model.pt              # 最新模型
├── best_model.pt         # 最佳模型
└── README.md            # 项目说明
```

## 主要改进

### 1. 训练策略优化
- **学习率调度器**: 实现了Noam学习率调度，包含预热阶段
- **标签平滑**: 使用0.1的标签平滑减少过拟合
- **梯度裁剪**: 防止梯度爆炸，提高训练稳定性
- **早停机制**: 基于验证集损失的早停，避免过拟合

### 2. 数据处理改进
- **数据分割**: 80%训练，10%验证，10%测试的标准分割
- **批处理优化**: 改进的批次创建和打乱机制
- **更好的掩码处理**: 优化的源语言和目标语言掩码

### 3. 模型保存机制
- **最佳模型保存**: 自动保存验证集上表现最佳的模型
- **检查点机制**: 定期保存训练检查点，支持中断恢复
- **完整状态保存**: 保存模型、优化器、训练轮数等完整状态

### 4. 评估和推理
- **详细评估**: 提供损失、困惑度等详细评估指标
- **示例翻译**: 评估时包含示例翻译展示
- **智能模型加载**: 优先加载最佳模型，向后兼容旧格式

## 快速开始

### 1. 环境准备
```bash
pip install torch numpy
```

### 2. 数据准备
确保 `data/` 目录下有平行语料文件：
- `MDN_Web_Docs.en-zh_CN.en` (英文)
- `MDN_Web_Docs.en-zh_CN.zh_CN` (中文)

### 3. 训练模型
```bash
python train.py
```

### 4. 评估模型
```bash
python evaluate.py
```

### 5. 推理测试
```bash
python inference.py
```

## 配置说明

主要配置在 `config.py` 文件中：

### 训练参数
- `epochs`: 训练轮数 (默认: 300)
- `batch_size`: 批次大小 (默认: 32)
- `learning_rate`: 初始学习率 (默认: 0.0001)
- `warmup_steps`: 预热步数 (默认: 4000)
- `grad_clip`: 梯度裁剪阈值 (默认: 1.0)
- `label_smoothing`: 标签平滑系数 (默认: 0.1)
- `patience`: 早停耐心值 (默认: 10)

### 模型参数
- `layers`: Transformer层数 (默认: 6)
- `d_model`: 模型维度 (默认: 512)
- `d_ff`: 前馈网络维度 (默认: 2048)
- `h_num`: 注意力头数 (默认: 8)
- `dropout`: Dropout率 (默认: 0.1)

## 训练监控

训练过程中会显示：
- 每个epoch的训练和验证损失
- 当前学习率
- 训练速度 (tokens/sec)
- 最佳模型保存提示
- 早停触发警告

## 模型文件

- `model.pt`: 最新训练的模型（包含完整训练状态）
- `best_model.pt`: 验证集上表现最佳的模型
- `checkpoints/`: 定期保存的训练检查点

## 性能优化建议

1. **GPU使用**: 确保CUDA可用以加速训练
2. **批次大小**: 根据GPU内存调整batch_size
3. **数据量**: 更多数据通常能提升模型效果
4. **超参数调优**: 可以根据具体任务调整学习率、层数等参数

## 常见问题

1. **内存不足**: 减小batch_size
2. **训练过慢**: 确保使用GPU，考虑减少模型层数
3. **过拟合**: 增加dropout，使用更多数据，调整早停参数
4. **欠拟合**: 增加模型容量，延长训练时间

## 技术特性

- 支持中断恢复训练
- 自动保存最佳模型
- 详细的训练日志
- 灵活的配置管理
- 向后兼容的模型加载
